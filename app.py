"""
INTERFACE WEB STREAMLIT POUR LE CHATBOT OLLAMA
===============================================
Lance avec: streamlit run app.py
"""

import streamlit as st
from chatbot_agent import ChatbotAgent
import time

# Configuration de la page
st.set_page_config(
    page_title="Chatbot IA Local (Ollama)",
    page_icon="ğŸ¤–",
    layout="wide"
)

# Initialisation de l'Ã©tat de session
if 'agent' not in st.session_state:
    st.session_state.agent = None
    st.session_state.messages = []
    st.session_state.show_analysis = False
    st.session_state.model_loaded = False

# Titre et description
st.title("ğŸ¤– Chatbot IA avec NLP (Version Ollama - Gratuite)")
st.markdown("Assistant intelligent 100% local - Vos donnÃ©es restent privÃ©es âœ…")

# Sidebar avec options
with st.sidebar:
    st.header("âš™ï¸ Configuration")
    
    # SÃ©lection du modÃ¨le
    st.subheader("ğŸ“¦ ModÃ¨le Ollama")
    
    models_info = {
        "mistral": "Ã‰quilibrÃ©, bon en franÃ§ais (7B) â­",
        "llama2": "Performant, anglais (7B)",
        "phi": "LÃ©ger et rapide (2.7B)",
        "neural-chat": "OptimisÃ© conversation (7B)",
        "openchat": "Bon pour dialogue (7B)"
    }
    
    selected_model = st.selectbox(
        "Choisir le modÃ¨le",
        options=list(models_info.keys()),
        format_func=lambda x: f"{x} - {models_info[x]}"
    )
    
    # TempÃ©rature
    temperature = st.slider(
        "TempÃ©rature (crÃ©ativitÃ©)",
        min_value=0.0,
        max_value=1.0,
        value=0.7,
        step=0.1,
        help="Plus haute = plus crÃ©atif, plus basse = plus prÃ©cis"
    )
    
    # Bouton de chargement du modÃ¨le
    if st.button("ğŸš€ Charger le modÃ¨le", type="primary"):
        with st.spinner(f"Chargement de {selected_model}..."):
            try:
                st.session_state.agent = ChatbotAgent(
                    model_name=selected_model,
                    temperature=temperature
                )
                st.session_state.model_loaded = True
                st.session_state.messages = []
                st.success(f"âœ… ModÃ¨le {selected_model} chargÃ© !")
                time.sleep(1)
                st.rerun()
            except Exception as e:
                st.error(f"âŒ Erreur: {e}")
                st.info("""
                **Installation Ollama:**
                1. TÃ©lÃ©chargez depuis https://ollama.com
                2. Installez Ollama
                3. Ouvrez un terminal et tapez:
                   ```
                   ollama pull mistral
                   ```
                4. Relancez cette application
                """)
                st.session_state.model_loaded = False
    
    st.divider()
    
    # Options d'affichage
    st.header("ğŸ” Options")
    st.session_state.show_analysis = st.checkbox(
        "Afficher l'analyse NLP",
        value=st.session_state.show_analysis
    )
    
    # Bouton pour effacer l'historique
    if st.button("ğŸ—‘ï¸ Effacer la conversation"):
        if st.session_state.agent:
            st.session_state.agent.clear_memory()
        st.session_state.messages = []
        st.rerun()
    
    st.divider()
    
    # Informations sur le modÃ¨le
    if st.session_state.model_loaded and st.session_state.agent:
        st.header("ğŸ“‹ Informations")
        info = st.session_state.agent.get_model_info()
        st.write(f"**ModÃ¨le:** {info['model']}")
        st.write(f"**Type:** {info['type']}")
        st.write(f"**CoÃ»t:** {info['cost']}")
        st.write(f"**ConfidentialitÃ©:** {info['privacy']}")
        
        st.divider()
        
        # Statistiques
        st.header("ğŸ“Š Statistiques")
        stats = st.session_state.agent.get_stats()
        
        col1, col2 = st.columns(2)
        with col1:
            st.metric("Messages", stats['total_messages'])
        with col2:
            if stats['total_messages'] > 0:
                positive_pct = (stats['sentiments']['positif'] / stats['total_messages']) * 100
                st.metric("Positif", f"{positive_pct:.0f}%")
        
        # Graphique des sentiments
        if stats['total_messages'] > 0:
            st.subheader("Sentiments")
            sentiment_data = stats['sentiments']
            st.bar_chart(sentiment_data)
            
            if stats['intents']:
                st.subheader("Intentions")
                intent_data = stats['intents']
                st.bar_chart(intent_data)

# Zone principale
if not st.session_state.model_loaded:
    st.info("ğŸ‘ˆ Veuillez charger un modÃ¨le Ollama dans la barre latÃ©rale pour commencer")
    
    # Guide d'installation
    with st.expander("ğŸ“š Guide d'installation Ollama"):
        st.markdown("""
        ### Installation Ollama (Gratuit)
        
        **1. TÃ©lÃ©charger Ollama:**
        - Windows/Mac: https://ollama.com/download
        - Linux: `curl -fsSL https://ollama.com/install.sh | sh`
        
        **2. TÃ©lÃ©charger un modÃ¨le:**
        ```bash
        ollama pull mistral
        ```
        
        **3. VÃ©rifier l'installation:**
        ```bash
        ollama list
        ```
        
        **4. Lancer cette application**
        
        ### ModÃ¨les recommandÃ©s:
        - **mistral** (7B) - Meilleur compromis, bon en franÃ§ais
        - **llama2** (7B) - Performant mais principalement anglais
        - **phi** (2.7B) - LÃ©ger et rapide pour machines modestes
        - **neural-chat** (7B) - OptimisÃ© pour la conversation
        
        ### Commandes utiles:
        - `ollama list` - Voir les modÃ¨les installÃ©s
        - `ollama pull <modÃ¨le>` - TÃ©lÃ©charger un modÃ¨le
        - `ollama rm <modÃ¨le>` - Supprimer un modÃ¨le
        """)
    
    st.warning("âš ï¸ Assurez-vous qu'Ollama est installÃ© et qu'un modÃ¨le est tÃ©lÃ©chargÃ©")

else:
    # Zone de chat
    chat_container = st.container()
    
    # Afficher l'historique des messages
    with chat_container:
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.write(message["content"])
                
                # Afficher l'analyse si disponible
                if st.session_state.show_analysis and "analysis" in message:
                    with st.expander("ğŸ” Analyse NLP"):
                        analysis = message["analysis"]
                        
                        col1, col2 = st.columns(2)
                        with col1:
                            sentiment = analysis['sentiment']['sentiment']
                            score = analysis['sentiment']['score']
                            
                            # Emoji selon le sentiment
                            emoji = "ğŸ˜Š" if sentiment == "positif" else "ğŸ˜" if sentiment == "neutre" else "ğŸ˜”"
                            st.write(f"**Sentiment:** {emoji} {sentiment}")
                            st.write(f"**Score:** {score:.2f}")
                        with col2:
                            intent = analysis['intent']
                            intent_emoji = {
                                'salutation': 'ğŸ‘‹',
                                'au_revoir': 'ğŸ‘‹',
                                'question': 'â“',
                                'aide': 'ğŸ†˜',
                                'remerciement': 'ğŸ™',
                                'conversation': 'ğŸ’¬'
                            }
                            st.write(f"**Intention:** {intent_emoji.get(intent, 'ğŸ’¬')} {intent}")
                        
                        if analysis['entities']:
                            st.write("**EntitÃ©s dÃ©tectÃ©es:**")
                            for entity in analysis['entities']:
                                st.write(f"- {entity['text']} ({entity['label']})")
    
    # Input utilisateur
    if prompt := st.chat_input("Ã‰crivez votre message..."):
        # Ajouter le message utilisateur
        st.session_state.messages.append({"role": "user", "content": prompt})
        
        with st.chat_message("user"):
            st.write(prompt)
        
        # GÃ©nÃ©rer la rÃ©ponse
        with st.chat_message("assistant"):
            with st.spinner("ğŸ¤” RÃ©flexion en cours..."):
                result = st.session_state.agent.generate_response(
                    prompt,
                    show_analysis=st.session_state.show_analysis
                )
                
                st.write(result['response'])
                
                # Afficher l'analyse
                if st.session_state.show_analysis and 'analysis' in result:
                    with st.expander("ğŸ” Analyse NLP"):
                        analysis = result['analysis']
                        
                        col1, col2 = st.columns(2)
                        with col1:
                            sentiment = analysis['sentiment']['sentiment']
                            score = analysis['sentiment']['score']
                            
                            emoji = "ğŸ˜Š" if sentiment == "positif" else "ğŸ˜" if sentiment == "neutre" else "ğŸ˜”"
                            st.write(f"**Sentiment:** {emoji} {sentiment}")
                            st.write(f"**Score:** {score:.2f}")
                        with col2:
                            intent = analysis['intent']
                            intent_emoji = {
                                'salutation': 'ğŸ‘‹',
                                'au_revoir': 'ğŸ‘‹',
                                'question': 'â“',
                                'aide': 'ğŸ†˜',
                                'remerciement': 'ğŸ™',
                                'conversation': 'ğŸ’¬'
                            }
                            st.write(f"**Intention:** {intent_emoji.get(intent, 'ğŸ’¬')} {intent}")
                        
                        if analysis['entities']:
                            st.write("**EntitÃ©s dÃ©tectÃ©es:**")
                            for entity in analysis['entities']:
                                st.write(f"- {entity['text']} ({entity['label']})")
        
        # Ajouter Ã  l'historique
        message_data = {"role": "assistant", "content": result['response']}
        if 'analysis' in result:
            message_data['analysis'] = result['analysis']
        st.session_state.messages.append(message_data)
        
        st.rerun()

# Footer
st.divider()
st.markdown("""
<div style='text-align: center; color: #666;'>
    <small>Chatbot 100% local et gratuit - PropulsÃ© par Ollama + LangChain + spaCy</small><br>
    <small>Vos donnÃ©es ne quittent jamais votre machine ğŸ”’</small>
</div>
""", unsafe_allow_html=True)